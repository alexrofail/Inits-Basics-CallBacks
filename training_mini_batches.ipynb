{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_mini_batches.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyML9x6c+lSeHl4NuWWhSPLJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexrofail/Loss-Optimizers-Training-Loops/blob/main/training_mini_batches.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-5SIgTPLLja"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "import gzip\n",
        "import pickle\n",
        "from torch import tensor\n",
        "from torch import nn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkwzTcmFLmUP"
      },
      "source": [
        "def get_data():\n",
        "    with gzip.open('mnist.pkl.gz') as f:\n",
        "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
        "    return map(tensor, (x_train,y_train,x_valid,y_valid))\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-aqneD8MHKD"
      },
      "source": [
        "x_train,y_train,x_valid,y_valid = get_data()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDf5TUNpMLII"
      },
      "source": [
        "import pickle, gzip, math, torch, matplotlib as mpl"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywrAQ0VIZ1tY"
      },
      "source": [
        "mpl.rcParams['image.cmap'] = 'gray'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3AaN8b9Z8ZN"
      },
      "source": [
        "n, m = x_train.shape\n",
        "c = y_train.max()+1\n",
        "nh = 50"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzWbSWGJaKWH"
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, nin, nh, nout):\n",
        "    super().__init__()\n",
        "    self.layers = [nn.Linear(nin,nh), nn.ReLU(), nn.Linear(nh,nout)]\n",
        "\n",
        "  def __call__(self, x):\n",
        "    for l in self.layers: x = l(x)\n",
        "    return x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cREyth4a5ux"
      },
      "source": [
        "model = Model(m, nh, 10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrrWCCKzb3kq"
      },
      "source": [
        "pred = model(x_train)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2-xSPGUb6EM"
      },
      "source": [
        "#Now we need a loss function"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DsQ8lruDc4w"
      },
      "source": [
        "#For loss funcs we need to first compute the softmax of our activations\n",
        "def log_softmax(x):\n",
        "  return (x.exp()/(x.exp().sum(-1, keepdim=True))).log() #NLL requires log softmax in Pytorch"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEVtxdsTEKUy"
      },
      "source": [
        "sm_pred = log_softmax(pred)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlCQ58v8EQgO"
      },
      "source": [
        "#Cross Entropy Loss\n",
        "#Sum of the actual * log prob(actual)\n",
        "#But in this case, our actuals are 1-hot-encoded, it can be done as -log(p_sub_i) where sub_i is he index of desired target"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BY27kmvSHCla",
        "outputId": "8f20a990-ef23-4eef-e9d2-44c6bdb94fca"
      },
      "source": [
        "#First three elements of dependent var\n",
        "y_train[:3]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNIxy3usHMum",
        "outputId": "f253a7d2-870b-4e13-ecba-fabdb1121934"
      },
      "source": [
        "sm_pred[[0,1,2], [5,0,4]]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.2974, -2.4392, -2.4061], grad_fn=<IndexBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bk3jScUVHbgw",
        "outputId": "bde6a71f-9d1b-418e-b448-bfa2ab758cca"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl4hF1L0Hdcv"
      },
      "source": [
        "def nll(input, target): return -input[range(target.shape[0]), target].mean()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diiXd-VBIiOT",
        "outputId": "53b81d69-26fd-40ee-d73b-7dc12a010113"
      },
      "source": [
        "loss = nll(sm_pred, y_train)\n",
        "loss"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3025, grad_fn=<NegBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBPRV_btI4BK"
      },
      "source": [
        "#We can refactor log_softmax(x)\n",
        "def log_softmax(x):\n",
        "  return x - x.exp().sum(-1, keepdim=True).log()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFpXE-TiKThC"
      },
      "source": [
        "#TODO: import the test near function to test these refactorings"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3cd_pe0LErp"
      },
      "source": [
        "def logsumexp(x):\n",
        "  max = x.max(-1)[0]\n",
        "  return m + (x - m[:,None]).exp().sum(-1).log()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt5dy260OHRJ"
      },
      "source": [
        "#Now refactor log_softmax to use logsumexp\n",
        "def log_softmax(x):\n",
        "  return x - x.logsumexp(-1, keepdim=True)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzxAOodCQHhR"
      },
      "source": [
        "#In pytorch log_softmax and nll_loss are combined in F.cross_entropy"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PNvvfTDOqBA"
      },
      "source": [
        "loss_func = F.cross_entropy"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RogNdnXNPPSp"
      },
      "source": [
        "#Define a metric: accuracy \n",
        "def accuracy(out, yb):\n",
        "  return (torch.argmax(out, dim=1)==yb).float().mean()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2mFjIM8QxVF",
        "outputId": "82e6dcb6-18e8-49b9-f98c-1e05704a7842"
      },
      "source": [
        "bs = 64\n",
        "\n",
        "xb = x_train[0:bs]\n",
        "\n",
        "preds = model(xb)\n",
        "preds[0], preds.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.0041, -0.0308, -0.0613,  0.2116, -0.1290,  0.0555,  0.0963,  0.0706,\n",
              "          0.0945,  0.1525], grad_fn=<SelectBackward>), torch.Size([64, 10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3lG3H2AeWpz",
        "outputId": "34fdd108-76c8-48b9-9662-e78db5675c1b"
      },
      "source": [
        "yb = y_train[0:bs]\n",
        "loss_func(preds,yb)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3062, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-3nr-TURHnZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e20fadf5-8922-48be-eb03-5f0fc9bde4a5"
      },
      "source": [
        "accuracy(preds, yb)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1406)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIY8PeTWdrBR"
      },
      "source": [
        "lr = 0.5\n",
        "\n",
        "epochs =1"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOhx3eNxfho5"
      },
      "source": [
        "#Training loop\n",
        "#Part 1, Lesson 2 reference\n",
        "for epoch in range(epochs):\n",
        "  for i in range((n-1)// bs+1):\n",
        "    start_i = i*bs\n",
        "    end_i = start_i +bs\n",
        "    xb = x_train[start_i:end_i]\n",
        "    yb = y_train[start_i:end_i]\n",
        "    loss = loss_func(model(xb), yb)\n",
        "\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "      for l in model.layers:\n",
        "        if hasattr(l, 'weight'):\n",
        "          l.weight -= l.weight.grad * lr\n",
        "          l.bias -= l.bias.grad * lr\n",
        "          l.weight.grad.zero_()\n",
        "          l.bias.grad.zero_()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSxASNNWC1Fa",
        "outputId": "1932993b-0124-46bd-9602-c516230b8199"
      },
      "source": [
        "loss_func(model(xb),yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.3986, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFwFL1kTDXP4"
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, nin, nh, nout):\n",
        "    super().__init__()\n",
        "    self.l1 = nn.Linear(nin, nh)\n",
        "    self.l2 = nn.Linear(nh, nout)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    return self.l2(F.relu(self.l1(x)))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ8OB7VzGEFt"
      },
      "source": [
        "model = Model(m, nh, 10)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcmSLIc8GIQL",
        "outputId": "684c7f50-c720-466c-d925-85e66b216ebb"
      },
      "source": [
        "for name,l in model.named_children(): print(f\"{name}: {l}\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "l1: Linear(in_features=784, out_features=50, bias=True)\n",
            "l2: Linear(in_features=50, out_features=10, bias=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-MBICOoGRzt",
        "outputId": "3bf89131-9a3f-46fc-fee2-c6e0acf16ac7"
      },
      "source": [
        "model.l1"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=784, out_features=50, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2vHECZzGTXH"
      },
      "source": [
        "#refactored training loop, instead of looping through each layer in the backward we can go straight through params\n",
        "def fit():\n",
        "  for epoch in range(epochs):\n",
        "    for i in range((n-1)// bs+1):\n",
        "      start_i = i*bs\n",
        "      end_i = start_i +bs\n",
        "      xb = x_train[start_i:end_i]\n",
        "      yb = y_train[start_i:end_i]\n",
        "      loss = loss_func(model(xb), yb)\n",
        "\n",
        "      loss.backward()\n",
        "      with torch.no_grad():\n",
        "        for p in model.parameters(): p -= p.grad*lr\n",
        "        model.zero_grad()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rv6ElIEPGsbp",
        "outputId": "6a491b07-132c-4c91-972c-a946a79182d5"
      },
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1138, grad_fn=<NllLossBackward>), tensor(1.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw0woQrbG47P"
      },
      "source": [
        "#This is PyTOrch's nn.sequential\n",
        "class SequentialModel(nn.Module):\n",
        "  def __init__(self, layers):\n",
        "    super().__init__()\n",
        "    self.layers = nn.ModuleList(layers)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    for l in self.layers: x = l(x)\n",
        "    return x"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-9-JDKWITlY"
      },
      "source": [
        "layers = [nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh, 10)]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI7DOiJSIJ8w"
      },
      "source": [
        "model = SequentialModel(layers)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56s2facVIMi_",
        "outputId": "d4ddf16a-90d5-4421-ce69-13db055b9342"
      },
      "source": [
        "model"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequentialModel(\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrZfPvTnIiuP"
      },
      "source": [
        "#Optimizers\n",
        "#to replace our with torch.no grad stuff in fit()\n",
        "\n",
        "#In Pytorch this is the optim.SGD stuff\n",
        "class Optimizer():\n",
        "  def __init__(self, params, lr = 0.5):\n",
        "    self.params, self.lr = list(params), lr\n",
        "\n",
        "  def step(self):\n",
        "    with torch.no_grad():\n",
        "        for p in model.parameters(): p -= p.grad*lr\n",
        "\n",
        "  def zero_grad(self):\n",
        "    for p in self.params: p.grad.data.zero_()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwwQjIQouWmg"
      },
      "source": [
        "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh,10))\n",
        "opt = Optimizer(model.parameters())"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lk0evTv-usYz"
      },
      "source": [
        "#Now we can refactor fit() to use our optimizer\n",
        "def fit():\n",
        "  for epoch in range(epochs):\n",
        "    for i in range((n-1)// bs+1):\n",
        "      start_i = i*bs\n",
        "      end_i = start_i +bs\n",
        "      xb = x_train[start_i:end_i]\n",
        "      yb = y_train[start_i:end_i]\n",
        "      loss = loss_func(model(xb), yb)\n",
        "\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      opt.zero_grad()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sADy57k5vO0x",
        "outputId": "f68a6fc6-1b50-45a0-ec70-2adbe769cfaf"
      },
      "source": [
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(2.2954, grad_fn=<NllLossBackward>), tensor(0.0625))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgYeFUEyvS41"
      },
      "source": [
        "from torch import optim"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UhrJo1ixHsK"
      },
      "source": [
        "optim.SGD.step??"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d83FkTmaxJxw"
      },
      "source": [
        "def get_model():\n",
        "  model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh,10))\n",
        "  return model, optim.SGD(model.parameters(), lr=lr)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cioNjCh1xiVE",
        "outputId": "9cf1bc8e-4341-4040-e261-ec2a0870fd65"
      },
      "source": [
        "model, opt = get_model()\n",
        "loss_func(model(xb), yb)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3207, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MRN7dKJxq7N"
      },
      "source": [
        "class Dataset():\n",
        "  def __init__(self,x,y):\n",
        "    self.x ,self.y = x,y\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "\n",
        "  def __getitem__(self,i):\n",
        "    return self.x[i], self.y[i]"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NW0HQQSNHeo"
      },
      "source": [
        "train_ds, valid_ds = Dataset(x_train, y_train), Dataset(x_valid, y_valid)\n",
        "assert len(train_ds) == len(x_train)\n",
        "assert len(valid_ds) == len(x_valid)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkMK1NLmNtXL",
        "outputId": "5023a7ba-e1d7-47ba-a69f-a9483f5f6cc3"
      },
      "source": [
        "xb, yb = train_ds[0:5]\n",
        "assert xb.shape == (5, 28*28)\n",
        "assert yb.shape == (5,)\n",
        "xb,yb"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([5, 0, 4, 1, 9]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WP3zTNAcQO_d",
        "outputId": "f5495e55-6c2a-419c-d8f6-a23a22e6a9e7"
      },
      "source": [
        "xb"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2qLPEz8QPJL",
        "outputId": "ee0a8c6b-d902-4fdf-c784-295549f9cd2b"
      },
      "source": [
        "yb"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4, 1, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_xXLxC7NfMD"
      },
      "source": [
        "model, opt = get_model()"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LpKZ-JyNl9w"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range((n-1) // bs+1):\n",
        "      xb, yb = train_ds[i*bs : i*bs+bs]\n",
        "      pred = model(xb)\n",
        "      loss = loss_func(pred, yb)\n",
        "\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      opt.zero_grad()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huWSfYBjQceH",
        "outputId": "5cfdb6c0-7931-46e4-e836-d83b8889dc26"
      },
      "source": [
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.4560, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rsce6MPGQtCC"
      },
      "source": [
        "#Create a Dataloader class that takes a dataset and batch size to store away\n",
        "class Dataloader():\n",
        "  def __init__(self, ds, bs):\n",
        "    self.ds, self.bs = ds, bs\n",
        "\n",
        "  def __iter__(self):\n",
        "    for i in range(0, len(self.ds), self.bs): yield self.ds[i:i+self.bs]"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo3o9Ckkt9bu"
      },
      "source": [
        "train_dl = Dataloader(train_ds, bs)\n",
        "valid_dl = Dataloader(valid_ds, bs)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o0WIy6GuuyY"
      },
      "source": [
        "xb, yb = next(iter(valid_dl))\n",
        "assert xb.shape==(bs, 28*28)\n",
        "assert yb.shape== (bs,)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXGLs-pTwhXn"
      },
      "source": [
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "qgaq74HPu9tj",
        "outputId": "fc620b73-83a0-4d2a-caab-68b4f7d834b4"
      },
      "source": [
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhyLPbWIv9cp"
      },
      "source": [
        "def fit():\n",
        "  for epoch in range(epochs):\n",
        "    for xb, yb in train_dl:\n",
        "      pred = model(xb)\n",
        "      loss = loss_func(pred, yb)\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      opt.zero_grad()"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY3pyeMKC3bY"
      },
      "source": [
        "#In loop we are currently going through data in the same order\n",
        "#Instead we need to shuffle it around and sample randomly\n",
        "\n",
        "class Sampler():\n",
        "  def __init__(self, ds, bs, shuffle=False):\n",
        "    self.n, self.bs, self.shuffle = len(ds), bs, shuffle\n",
        "\n",
        "  def __iter__(self):\n",
        "    self.idxs = torch.randperm(self.n) if self.shuffle else torch.arange(self.n)\n",
        "    for i in range(0, self.n, self.bs) : yield self.idxs[i:i+self.bs]"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYgGFPpvDpcj"
      },
      "source": [
        "small_ds = Dataset(*train_ds[:10])"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNnaxXQeDwV7",
        "outputId": "820ecd96-7db8-4b68-c9dc-9411d1506287"
      },
      "source": [
        "s = Sampler(small_ds, 3, False)\n",
        "[o for o in s]"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7, 8]), tensor([9])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLeU-DW3D38j",
        "outputId": "02b52c03-2d11-46f5-c12b-9018b605d4f6"
      },
      "source": [
        "s = Sampler(small_ds, 3, True)\n",
        "[o for o in s]"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([2, 0, 3]), tensor([8, 7, 4]), tensor([6, 1, 5]), tensor([9])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzdYcEErEcmO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}